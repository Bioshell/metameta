# Template for adding new tools to MetaMeta pipeline
# Replace all occurences of newtool with your tool identifier

# Download
rule newtool_db_1:
	output: db_path['newtool'] + "database.tar.gz"
	log: config['dbdir'] + "log/newtool_db_1.log"
	benchmark: config['dbdir'] + "log/newtool_db_1.time"
	run:
		shell(download("http://www.files.com/database.tar.gz", output[0]) + " > {log} 2>&1")
	
# Unpack
rule newtool_db_2:
	input: db_path['newtool'] + "database.tar.gz"
	output: db_path['newtool'] + "sequences.fasta"
			, db_path['newtool'] + "database.index"
	log: config['dbdir'] + "log/newtool_db_2.log"
	benchmark: config['dbdir'] + "log/newtool_db_2.time"
	shell: "tar zxfv {input} -C {db_path[newtool]} > {log} 2>&1"
	
# Outputs a list with all accession version identifiers used (it generates the database profile)
rule newtool_db_profile:
	input: db_path['newtool'] + "sequences.fasta"
	output: config['dbdir'] + "newtool.dbaccession.out"
	log: config['dbdir'] + "log/newtool_db_profile.log"
	benchmark: config['dbdir'] + "log/newtool_db_profile.time"
	shell: "command {input} > {output} 2> {log}"

# Check if all required files are present
rule newtool_db_check:
	input: config['dbdir'] + "newtool.dbaccession.out"
			, db_path['newtool'] + "sequences.fasta"
			, db_path['newtool'] + "database.index"
	output: touch(config['dbdir'] + "newtool_db_check.done")
	log: config['dbdir'] + "log/newtool_db_check.log"
	benchmark: config['dbdir'] + "log/newtool_db_check.time"
	run: 
		if not config['keepfiles']: 
			shell(rmTempFilesDB(db_path["newtool"], input[1:]) + " > {log} 2>&1")
			shell(rmEmptyFolderDB(db_path["newtool"]) + " >> {log} 2>&1")
