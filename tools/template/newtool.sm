# Template for adding new tools to the MetaMeta pipeline
# Replace all occurences of newtool with your tool identifier, newtool_command with the tool call, newtool_database.out with the database file (or prefix), newtool.yaml to integrate with conda

# Run tool
rule newtool_run_1:
	input:
		fq1="{sample}/reads/newtool.1.fq",
		dbcheck=config['dbdir'] + "{database}/newtool_db_check.done"
	output:	"{sample}/newtool/{database}/{sample}.results.csv"
	log: "{sample}/log/{database}/newtool_run_1.log"
	benchmark: "{sample}/log/{database}/newtool_run_1.time"
	threads: config["threads"]
	conda: srcdir("../envs/newtool.yaml")
	params: reads_cmd = lambda wildcards: "--paired " + wildcards.sample + "/reads/newtool.1.fq " + wildcards.sample + "/reads/newtool.2.fq" if "fq2" in config["samples"][wildcards.sample] else "--single " + wildcards.sample + "/reads/newtool.1.fq"
	shell: "{config[tool_alt_path][newtool]}newtool_command --database {config[dbdir]}{wildcards.database}/newtool_db/newtool_database.out {params.reads_cmd} --threads {threads} > {output} 2> {log}"

# Generate output (check supported formats)
rule newtool_rpt:
	input: "{sample}/newtool/{database}/{sample}.results.csv"
	output: "{sample}/profiles/{database}/newtool.profile.out"
	log: "{sample}/log/{database}/newtool_rpt.log"
	benchmark: "{sample}/log/{database}/newtool_rpt.time"
	shell: "convert {input} > {output} 2> {log}"
